<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>Three Parameterizations of Rasch model</title>
<style type="text/css">
/**
 * Prism.s theme ported from highlight.js's xcode style
 */
pre code {
  padding: 1em;
}
.token.comment {
  color: #007400;
}
.token.punctuation {
  color: #999;
}
.token.tag,
.token.selector {
  color: #aa0d91;
}
.token.boolean,
.token.number,
.token.constant,
.token.symbol {
  color: #1c00cf;
}
.token.property,
.token.attr-name,
.token.string,
.token.char,
.token.builtin {
  color: #c41a16;
}
.token.inserted {
  background-color: #ccffd8;
}
.token.deleted {
  background-color: #ffebe9;
}
.token.operator,
.token.entity,
.token.url,
.language-css .token.string,
.style .token.string {
  color: #9a6e3a;
}
.token.atrule,
.token.attr-value,
.token.keyword {
  color: #836c28;
}
.token.function,
.token.class-name {
  color: #DD4A68;
}
.token.regex,
.token.important,
.token.variable {
  color: #5c2699;
}
.token.important,
.token.bold {
  font-weight: bold;
}
.token.italic {
  font-style: italic;
}
</style>
<style type="text/css">
body {
  font-family: sans-serif;
  max-width: 800px;
  margin: auto;
  padding: 1em;
  line-height: 1.5;
  box-sizing: border-box;
}
body, .footnotes, code { font-size: .9em; }
li li { font-size: .95em; }
*, *:before, *:after {
  box-sizing: inherit;
}
pre, img { max-width: 100%; }
pre, pre:hover {
  white-space: pre-wrap;
  word-break: break-all;
}
pre code {
  display: block;
  overflow-x: auto;
}
code { font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace; }
:not(pre) > code, code[class] { background-color: #F8F8F8; }
code.language-undefined, pre > code:not([class]) {
  background-color: inherit;
  border: 1px solid #eee;
}
table {
  margin: auto;
  border-top: 1px solid #666;
}
table thead th { border-bottom: 1px solid #ddd; }
th, td { padding: 5px; }
thead, tfoot, tr:nth-child(even) { background: #eee; }
blockquote {
  color: #666;
  margin: 0;
  padding-left: 1em;
  border-left: 0.5em solid #eee;
}
hr, .footnotes::before { border: 1px dashed #ddd; }
.frontmatter { text-align: center; }
#TOC .numbered li { list-style: none; }
#TOC .numbered { padding-left: 0; }
#TOC .numbered ul { padding-left: 1em; }
table, .body h2 { border-bottom: 1px solid #666; }
.body .appendix, .appendix ~ h2 { border-bottom-style: dashed; }
.footnote-ref a::before { content: "["; }
.footnote-ref a::after { content: "]"; }
.footnotes::before {
  content: "";
  display: block;
  max-width: 20em;
}

@media print {
  body {
    font-size: 12pt;
    max-width: 100%;
  }
  tr, img { page-break-inside: avoid; }
}
@media only screen and (min-width: 992px) {
  pre { white-space: pre; }
}
</style>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css">
</head>
<body>
<div class="include-before">
</div>
<div class="frontmatter">
<div class="title"><h1>Three Parameterizations of Rasch model</h1></div>
<div class="author"><h2></h2></div>
<div class="date"><h3></h3></div>
</div>
<div class="body">
<h1 id="three-parameterizations-of-rasch-model">Three Parameterizations of Rasch model</h1>
<p>Here we demonstrate three alternative ways to represent the simple Rasch model for dichotomous
data.</p>
<h2 id="approach-1">Approach 1</h2>
<p>Use fixed slope parameters set to 1, freely estimate all intercepts, and freely estimate the
variance of the latent trait.</p>
<pre><code class="language-r">library(mirt)
dat &lt;- expand.table(LSAT6)
mod &lt;- mirt(dat, 1, itemtype = 'Rasch')
</code></pre>
<pre><code>## 
Iteration: 1, Log-Lik: -2473.219, Max-Change: 0.05796
Iteration: 2, Log-Lik: -2471.905, Max-Change: 0.03951
Iteration: 3, Log-Lik: -2471.040, Max-Change: 0.03366
Iteration: 4, Log-Lik: -2470.482, Max-Change: 0.03644
Iteration: 5, Log-Lik: -2469.693, Max-Change: 0.02590
Iteration: 6, Log-Lik: -2469.239, Max-Change: 0.02211
Iteration: 7, Log-Lik: -2468.875, Max-Change: 0.01999
Iteration: 8, Log-Lik: -2468.573, Max-Change: 0.01718
Iteration: 9, Log-Lik: -2468.330, Max-Change: 0.01528
Iteration: 10, Log-Lik: -2468.157, Max-Change: 0.01742
Iteration: 11, Log-Lik: -2467.932, Max-Change: 0.01255
Iteration: 12, Log-Lik: -2467.789, Max-Change: 0.01111
Iteration: 13, Log-Lik: -2467.669, Max-Change: 0.01035
Iteration: 14, Log-Lik: -2467.565, Max-Change: 0.00911
Iteration: 15, Log-Lik: -2467.480, Max-Change: 0.00826
Iteration: 16, Log-Lik: -2467.417, Max-Change: 0.00961
Iteration: 17, Log-Lik: -2467.338, Max-Change: 0.00701
Iteration: 18, Log-Lik: -2467.285, Max-Change: 0.00632
Iteration: 19, Log-Lik: -2467.240, Max-Change: 0.00600
Iteration: 20, Log-Lik: -2467.200, Max-Change: 0.00534
Iteration: 21, Log-Lik: -2467.166, Max-Change: 0.00491
Iteration: 22, Log-Lik: -2467.141, Max-Change: 0.00569
Iteration: 23, Log-Lik: -2467.110, Max-Change: 0.00424
Iteration: 24, Log-Lik: -2467.088, Max-Change: 0.00386
Iteration: 25, Log-Lik: -2467.069, Max-Change: 0.00371
Iteration: 26, Log-Lik: -2467.052, Max-Change: 0.00332
Iteration: 27, Log-Lik: -2467.038, Max-Change: 0.00307
Iteration: 28, Log-Lik: -2467.027, Max-Change: 0.00351
Iteration: 29, Log-Lik: -2467.014, Max-Change: 0.00269
Iteration: 30, Log-Lik: -2467.005, Max-Change: 0.00247
Iteration: 31, Log-Lik: -2466.997, Max-Change: 0.00238
Iteration: 32, Log-Lik: -2466.989, Max-Change: 0.00214
Iteration: 33, Log-Lik: -2466.983, Max-Change: 0.00199
Iteration: 34, Log-Lik: -2466.978, Max-Change: 0.00233
Iteration: 35, Log-Lik: -2466.973, Max-Change: 0.00176
Iteration: 36, Log-Lik: -2466.968, Max-Change: 0.00162
Iteration: 37, Log-Lik: -2466.965, Max-Change: 0.00157
Iteration: 38, Log-Lik: -2466.961, Max-Change: 0.00142
Iteration: 39, Log-Lik: -2466.959, Max-Change: 0.00132
Iteration: 40, Log-Lik: -2466.956, Max-Change: 0.00154
Iteration: 41, Log-Lik: -2466.954, Max-Change: 0.00117
Iteration: 42, Log-Lik: -2466.952, Max-Change: 0.00108
Iteration: 43, Log-Lik: -2466.950, Max-Change: 0.00104
Iteration: 44, Log-Lik: -2466.949, Max-Change: 0.00095
Iteration: 45, Log-Lik: -2466.947, Max-Change: 0.00088
Iteration: 46, Log-Lik: -2466.946, Max-Change: 0.00100
Iteration: 47, Log-Lik: -2466.945, Max-Change: 0.00079
Iteration: 48, Log-Lik: -2466.944, Max-Change: 0.00073
Iteration: 49, Log-Lik: -2466.944, Max-Change: 0.00071
Iteration: 50, Log-Lik: -2466.943, Max-Change: 0.00065
Iteration: 51, Log-Lik: -2466.942, Max-Change: 0.00060
Iteration: 52, Log-Lik: -2466.942, Max-Change: 0.00070
Iteration: 53, Log-Lik: -2466.941, Max-Change: 0.00054
Iteration: 54, Log-Lik: -2466.941, Max-Change: 0.00050
Iteration: 55, Log-Lik: -2466.940, Max-Change: 0.00048
Iteration: 56, Log-Lik: -2466.940, Max-Change: 0.00044
Iteration: 57, Log-Lik: -2466.940, Max-Change: 0.00041
Iteration: 58, Log-Lik: -2466.940, Max-Change: 0.00051
Iteration: 59, Log-Lik: -2466.939, Max-Change: 0.00036
Iteration: 60, Log-Lik: -2466.939, Max-Change: 0.00034
Iteration: 61, Log-Lik: -2466.939, Max-Change: 0.00033
Iteration: 62, Log-Lik: -2466.939, Max-Change: 0.00030
Iteration: 63, Log-Lik: -2466.939, Max-Change: 0.00028
Iteration: 64, Log-Lik: -2466.939, Max-Change: 0.00031
Iteration: 65, Log-Lik: -2466.938, Max-Change: 0.00025
Iteration: 66, Log-Lik: -2466.938, Max-Change: 0.00023
Iteration: 67, Log-Lik: -2466.938, Max-Change: 0.00023
Iteration: 68, Log-Lik: -2466.938, Max-Change: 0.00021
Iteration: 69, Log-Lik: -2466.938, Max-Change: 0.00019
Iteration: 70, Log-Lik: -2466.938, Max-Change: 0.00022
Iteration: 71, Log-Lik: -2466.938, Max-Change: 0.00017
Iteration: 72, Log-Lik: -2466.938, Max-Change: 0.00016
Iteration: 73, Log-Lik: -2466.938, Max-Change: 0.00016
Iteration: 74, Log-Lik: -2466.938, Max-Change: 0.00014
Iteration: 75, Log-Lik: -2466.938, Max-Change: 0.00014
Iteration: 76, Log-Lik: -2466.938, Max-Change: 0.00013
Iteration: 77, Log-Lik: -2466.938, Max-Change: 0.00012
Iteration: 78, Log-Lik: -2466.938, Max-Change: 0.00011
Iteration: 79, Log-Lik: -2466.938, Max-Change: 0.00011
Iteration: 80, Log-Lik: -2466.938, Max-Change: 0.00010
</code></pre>
<pre><code class="language-r">print(mod)
</code></pre>
<pre><code>## 
## Call:
## mirt(data = dat, model = 1, itemtype = &quot;Rasch&quot;)
## 
## Full-information item factor analysis with 1 factor(s).
## Converged within 1e-04 tolerance after 80 EM iterations.
## mirt version: 1.39.4 
## M-step optimizer: nlminb 
## EM acceleration: Ramsay 
## Number of rectangular quadrature: 61
## Latent density type: Gaussian 
## 
## Log-likelihood = -2466.938
## Estimated parameters: 6 
## AIC = 4945.875
## BIC = 4975.322; SABIC = 4956.266
## G2 (25) = 21.8, p = 0.6474
## RMSEA = 0, CFI = NaN, TLI = NaN
</code></pre>
<pre><code class="language-r">coef(mod)
</code></pre>
<pre><code>## $Item_1
##     a1     d g u
## par  1 2.731 0 1
## 
## $Item_2
##     a1     d g u
## par  1 0.999 0 1
## 
## $Item_3
##     a1    d g u
## par  1 0.24 0 1
## 
## $Item_4
##     a1     d g u
## par  1 1.307 0 1
## 
## $Item_5
##     a1   d g u
## par  1 2.1 0 1
## 
## $GroupPars
##     MEAN_1 COV_11
## par      0  0.572
</code></pre>
<h2 id="approach-2">Approach 2</h2>
<p>Use freely estimate slope parameters but constrain them to be equal across all items, freely
estimate all intercepts.</p>
<pre><code class="language-r">model &lt;- mirt.model('Theta = 1-5
                    CONSTRAIN = (1-5, a1)')
mod2 &lt;- mirt(dat, model)
</code></pre>
<pre><code>## 
Iteration: 1, Log-Lik: -2468.601, Max-Change: 0.07077
Iteration: 2, Log-Lik: -2467.371, Max-Change: 0.02297
Iteration: 3, Log-Lik: -2467.099, Max-Change: 0.01355
Iteration: 4, Log-Lik: -2466.986, Max-Change: 0.00735
Iteration: 5, Log-Lik: -2466.959, Max-Change: 0.00482
Iteration: 6, Log-Lik: -2466.947, Max-Change: 0.00316
Iteration: 7, Log-Lik: -2466.939, Max-Change: 0.00109
Iteration: 8, Log-Lik: -2466.938, Max-Change: 0.00073
Iteration: 9, Log-Lik: -2466.938, Max-Change: 0.00049
Iteration: 10, Log-Lik: -2466.938, Max-Change: 0.00028
Iteration: 11, Log-Lik: -2466.938, Max-Change: 0.00016
Iteration: 12, Log-Lik: -2466.938, Max-Change: 0.00009
</code></pre>
<pre><code class="language-r">print(mod2)
</code></pre>
<pre><code>## 
## Call:
## mirt(data = dat, model = model)
## 
## Full-information item factor analysis with 1 factor(s).
## Converged within 1e-04 tolerance after 12 EM iterations.
## mirt version: 1.39.4 
## M-step optimizer: BFGS 
## EM acceleration: Ramsay 
## Number of rectangular quadrature: 61
## Latent density type: Gaussian 
## 
## Log-likelihood = -2466.938
## Estimated parameters: 10 
## AIC = 4945.875
## BIC = 4975.322; SABIC = 4956.265
## G2 (25) = 21.8, p = 0.6474
## RMSEA = 0, CFI = NaN, TLI = NaN
</code></pre>
<pre><code class="language-r">coef(mod2)
</code></pre>
<pre><code>## $Item_1
##        a1    d g u
## par 0.755 2.73 0 1
## 
## $Item_2
##        a1     d g u
## par 0.755 0.999 0 1
## 
## $Item_3
##        a1    d g u
## par 0.755 0.24 0 1
## 
## $Item_4
##        a1     d g u
## par 0.755 1.307 0 1
## 
## $Item_5
##        a1   d g u
## par 0.755 2.1 0 1
## 
## $GroupPars
##     MEAN_1 COV_11
## par      0      1
</code></pre>
<h2 id="approach-3">Approach 3</h2>
<p>Fix slopes to 1, freely estimate intercepts subject to the constraint that \(\sum_j d_j = 0\),
and freely estimate the latent mean and variance.</p>
<pre><code class="language-r">model2 &lt;- mirt.model('Theta = 1-5
                     MEAN = Theta
                     COV = Theta*Theta')

#view how vector of parameters is organized internally
sv &lt;- mirt(dat, model2, itemtype = 'Rasch', pars = 'values')
sv[sv$est, ]
</code></pre>
<pre><code>##    group   item     class   name parnum     value lbound ubound  est prior.type
## 2    all Item_1      dich      d      2 2.8152981   -Inf    Inf TRUE       none
## 6    all Item_2      dich      d      6 1.0818304   -Inf    Inf TRUE       none
## 10   all Item_3      dich      d     10 0.2618655   -Inf    Inf TRUE       none
## 14   all Item_4      dich      d     14 1.4071275   -Inf    Inf TRUE       none
## 18   all Item_5      dich      d     18 2.2136968   -Inf    Inf TRUE       none
## 21   all  GROUP GroupPars MEAN_1     21 0.0000000   -Inf    Inf TRUE       none
## 22   all  GROUP GroupPars COV_11     22 1.0000000  1e-04    Inf TRUE       none
##    prior_1 prior_2
## 2      NaN     NaN
## 6      NaN     NaN
## 10     NaN     NaN
## 14     NaN     NaN
## 18     NaN     NaN
## 21     NaN     NaN
## 22     NaN     NaN
</code></pre>
<pre><code class="language-r">#constraint: create function for solnp to compute constraint, and declare value in eqB
eqfun &lt;- function(p, optim_args) sum(p[1:5]) #could use browser() here, if it helps
solnp_args &lt;- list(eqfun=eqfun, eqB=0, LB = c(rep(-15, 6), 1e-4))

mod3 &lt;- mirt(dat, model2, itemtype = 'Rasch', optimizer = 'solnp', solnp_args=solnp_args,
			 pars=sv)
</code></pre>
<pre><code>## 
Iteration: 1, Log-Lik: -2473.219, Max-Change: 2.01548
Iteration: 2, Log-Lik: -2978.093, Max-Change: 0.64564
Iteration: 3, Log-Lik: -2637.888, Max-Change: 0.30377
Iteration: 4, Log-Lik: -2536.573, Max-Change: 0.16978
Iteration: 5, Log-Lik: -2498.679, Max-Change: 0.10519
Iteration: 6, Log-Lik: -2482.438, Max-Change: 0.06941
Iteration: 7, Log-Lik: -2474.859, Max-Change: 0.04771
Iteration: 8, Log-Lik: -2471.120, Max-Change: 0.03371
Iteration: 9, Log-Lik: -2469.203, Max-Change: 0.02429
Iteration: 10, Log-Lik: -2468.200, Max-Change: 0.01951
Iteration: 11, Log-Lik: -2467.607, Max-Change: 0.01270
Iteration: 12, Log-Lik: -2467.329, Max-Change: 0.00946
Iteration: 13, Log-Lik: -2467.179, Max-Change: 0.00864
Iteration: 14, Log-Lik: -2467.073, Max-Change: 0.00542
Iteration: 15, Log-Lik: -2467.027, Max-Change: 0.00401
Iteration: 16, Log-Lik: -2467.001, Max-Change: 0.00343
Iteration: 17, Log-Lik: -2466.983, Max-Change: 0.00217
Iteration: 18, Log-Lik: -2466.975, Max-Change: 0.00166
Iteration: 19, Log-Lik: -2466.969, Max-Change: 0.00190
Iteration: 20, Log-Lik: -2466.964, Max-Change: 0.00105
Iteration: 21, Log-Lik: -2466.961, Max-Change: 0.00106
Iteration: 22, Log-Lik: -2466.958, Max-Change: 0.00110
Iteration: 23, Log-Lik: -2466.955, Max-Change: 0.00077
Iteration: 24, Log-Lik: -2466.954, Max-Change: 0.00110
Iteration: 25, Log-Lik: -2466.952, Max-Change: 0.00105
Iteration: 26, Log-Lik: -2466.950, Max-Change: 0.00098
Iteration: 27, Log-Lik: -2466.948, Max-Change: 0.00093
Iteration: 28, Log-Lik: -2466.947, Max-Change: 0.00090
Iteration: 29, Log-Lik: -2466.946, Max-Change: 0.00084
Iteration: 30, Log-Lik: -2466.945, Max-Change: 0.00079
Iteration: 31, Log-Lik: -2466.944, Max-Change: 0.00075
Iteration: 32, Log-Lik: -2466.943, Max-Change: 0.00020
Iteration: 33, Log-Lik: -2466.943, Max-Change: 0.00014
Iteration: 34, Log-Lik: -2466.943, Max-Change: 0.00010
</code></pre>
<pre><code class="language-r">print(mod3)
</code></pre>
<pre><code>## 
## Call:
## mirt(data = dat, model = model2, itemtype = &quot;Rasch&quot;, optimizer = &quot;solnp&quot;, 
##     pars = sv, solnp_args = solnp_args)
## 
## Full-information item factor analysis with 1 factor(s).
## Converged within 1e-04 tolerance after 34 EM iterations.
## mirt version: 1.39.4 
## M-step optimizer: solnp 
## EM acceleration: Ramsay 
## Number of rectangular quadrature: 61
## Latent density type: Gaussian 
## 
## Log-likelihood = -2466.943
## Estimated parameters: 7 
## AIC = 4947.887
## BIC = 4982.241; SABIC = 4960.009
## G2 (25) = 21.81, p = 0.6467
## RMSEA = 0, CFI = NaN, TLI = NaN
</code></pre>
<pre><code class="language-r">coef(mod3)
</code></pre>
<pre><code>## $Item_1
##     a1     d g u
## par  1 1.253 0 1
## 
## $Item_2
##     a1      d g u
## par  1 -0.475 0 1
## 
## $Item_3
##     a1      d g u
## par  1 -1.233 0 1
## 
## $Item_4
##     a1      d g u
## par  1 -0.168 0 1
## 
## $Item_5
##     a1     d g u
## par  1 0.623 0 1
## 
## $GroupPars
##     MEAN_1 COV_11
## par  1.472  0.559
</code></pre>
<pre><code class="language-r">(ds &lt;- sapply(coef(mod3)[1:5], function(x) x[,'d']))
</code></pre>
<pre><code>##     Item_1     Item_2     Item_3     Item_4     Item_5 
##  1.2529600 -0.4754484 -1.2327360 -0.1681705  0.6233949
</code></pre>
<pre><code class="language-r">sum(ds)
</code></pre>
<pre><code>## [1] 4.551914e-15
</code></pre>
<p>The following is equivalent to the above, however it uses the <code>nloptr</code> package instead (requires <code>mirt &gt; 1.24</code>).</p>
<pre><code class="language-r">library(nloptr)
heq &lt;- function(p, optim_args) sum(p[1:5])
heqjac &lt;- function(x, optim_args) nl.jacobian(x, heq)
nloptr_args &lt;- list(lb = c(rep(-15, 6), 1e-4),
                    eval_g_eq = heq,
                    eval_jac_g_eq = heqjac,
                    opts = list(algorithm = 'NLOPT_LD_SLSQP',
                                xtol_rel=1e-8)
)

mod4 &lt;- mirt(dat, model2, itemtype = 'Rasch', optimizer = 'nloptr', nloptr_args=nloptr_args,
             pars=sv)
</code></pre>
<pre><code>## 
Iteration: 1, Log-Lik: -2473.219, Max-Change: 2.01548
Iteration: 2, Log-Lik: -2978.093, Max-Change: 0.64564
Iteration: 3, Log-Lik: -2637.888, Max-Change: 0.30377
Iteration: 4, Log-Lik: -2536.573, Max-Change: 0.16978
Iteration: 5, Log-Lik: -2498.679, Max-Change: 0.10519
Iteration: 6, Log-Lik: -2482.438, Max-Change: 0.06941
Iteration: 7, Log-Lik: -2474.859, Max-Change: 0.04771
Iteration: 8, Log-Lik: -2471.120, Max-Change: 0.03371
Iteration: 9, Log-Lik: -2469.203, Max-Change: 0.02429
Iteration: 10, Log-Lik: -2468.200, Max-Change: 0.01951
Iteration: 11, Log-Lik: -2467.607, Max-Change: 0.01270
Iteration: 12, Log-Lik: -2467.329, Max-Change: 0.00946
Iteration: 13, Log-Lik: -2467.179, Max-Change: 0.00868
Iteration: 14, Log-Lik: -2467.079, Max-Change: 0.00517
Iteration: 15, Log-Lik: -2467.033, Max-Change: 0.00394
Iteration: 16, Log-Lik: -2467.007, Max-Change: 0.00438
Iteration: 17, Log-Lik: -2466.987, Max-Change: 0.00224
Iteration: 18, Log-Lik: -2466.977, Max-Change: 0.00175
Iteration: 19, Log-Lik: -2466.971, Max-Change: 0.00271
Iteration: 20, Log-Lik: -2466.965, Max-Change: 0.00105
Iteration: 21, Log-Lik: -2466.962, Max-Change: 0.00098
Iteration: 22, Log-Lik: -2466.959, Max-Change: 0.00240
Iteration: 23, Log-Lik: -2466.956, Max-Change: 0.00095
Iteration: 24, Log-Lik: -2466.954, Max-Change: 0.00092
Iteration: 25, Log-Lik: -2466.953, Max-Change: 0.00135
Iteration: 26, Log-Lik: -2466.951, Max-Change: 0.00086
Iteration: 27, Log-Lik: -2466.949, Max-Change: 0.00082
Iteration: 28, Log-Lik: -2466.948, Max-Change: 0.00081
Iteration: 29, Log-Lik: -2466.947, Max-Change: 0.00075
Iteration: 30, Log-Lik: -2466.946, Max-Change: 0.00071
Iteration: 31, Log-Lik: -2466.945, Max-Change: 0.00069
Iteration: 32, Log-Lik: -2466.944, Max-Change: 0.00064
Iteration: 33, Log-Lik: -2466.944, Max-Change: 0.00061
Iteration: 34, Log-Lik: -2466.943, Max-Change: 0.00059
Iteration: 35, Log-Lik: -2466.942, Max-Change: 0.00055
Iteration: 36, Log-Lik: -2466.942, Max-Change: 0.00052
Iteration: 37, Log-Lik: -2466.941, Max-Change: 0.00050
Iteration: 38, Log-Lik: -2466.941, Max-Change: 0.00047
Iteration: 39, Log-Lik: -2466.941, Max-Change: 0.00044
Iteration: 40, Log-Lik: -2466.940, Max-Change: 0.00042
Iteration: 41, Log-Lik: -2466.940, Max-Change: 0.00039
Iteration: 42, Log-Lik: -2466.940, Max-Change: 0.00037
Iteration: 43, Log-Lik: -2466.940, Max-Change: 0.00036
Iteration: 44, Log-Lik: -2466.939, Max-Change: 0.00033
Iteration: 45, Log-Lik: -2466.939, Max-Change: 0.00032
Iteration: 46, Log-Lik: -2466.939, Max-Change: 0.00030
Iteration: 47, Log-Lik: -2466.939, Max-Change: 0.00028
Iteration: 48, Log-Lik: -2466.939, Max-Change: 0.00027
Iteration: 49, Log-Lik: -2466.939, Max-Change: 0.00026
Iteration: 50, Log-Lik: -2466.938, Max-Change: 0.00024
Iteration: 51, Log-Lik: -2466.938, Max-Change: 0.00023
Iteration: 52, Log-Lik: -2466.938, Max-Change: 0.00022
Iteration: 53, Log-Lik: -2466.938, Max-Change: 0.00020
Iteration: 54, Log-Lik: -2466.938, Max-Change: 0.00019
Iteration: 55, Log-Lik: -2466.938, Max-Change: 0.00018
Iteration: 56, Log-Lik: -2466.938, Max-Change: 0.00017
Iteration: 57, Log-Lik: -2466.938, Max-Change: 0.00016
Iteration: 58, Log-Lik: -2466.938, Max-Change: 0.00015
Iteration: 59, Log-Lik: -2466.938, Max-Change: 0.00014
Iteration: 60, Log-Lik: -2466.938, Max-Change: 0.00014
Iteration: 61, Log-Lik: -2466.938, Max-Change: 0.00013
Iteration: 62, Log-Lik: -2466.938, Max-Change: 0.00012
Iteration: 63, Log-Lik: -2466.938, Max-Change: 0.00011
Iteration: 64, Log-Lik: -2466.938, Max-Change: 0.00011
Iteration: 65, Log-Lik: -2466.938, Max-Change: 0.00010
Iteration: 66, Log-Lik: -2466.938, Max-Change: 0.00010
</code></pre>
<pre><code class="language-r">(ds &lt;- sapply(coef(mod3)[1:5], function(x) x[,'d']))
</code></pre>
<pre><code>##     Item_1     Item_2     Item_3     Item_4     Item_5 
##  1.2529600 -0.4754484 -1.2327360 -0.1681705  0.6233949
</code></pre>
<pre><code class="language-r">sum(ds)
</code></pre>
<pre><code>## [1] 4.551914e-15
</code></pre>
</div>
<div class="include-after">
</div>
<script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/prism-core.min.js" defer></script>
<script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/autoloader/prism-autoloader.min.js" defer></script>
<script src="https://cdn.jsdelivr.net/combine/npm/katex/dist/katex.min.js,npm/katex/dist/contrib/auto-render.min.js,npm/@xiee/utils/js/render-katex.js" defer></script>
</body>
</html>
